### Data Veracity 数据准确性

> 我们是数据科学家，不是数据炼金术士。我们不能从数据中分析出黄金。

当大多数人认为大数据具有体量大、产生快和种类多的特征时，还有一个同等重要却常被忽略的维度：数据准确性。数据准确性是指综合质量情况和数据正确性。你必须评价数据的真实性和精准度，还要标识出丢失和不完整数据。俗话说：“垃圾进，垃圾出”如果你的数据是不精确的或者丢失了信息，你就不会分析出黄金。

评价数据真实性往往是主观的。你必须依赖于你的经验和对数据来源和内容的上下文环境理解。领域专家的专长就是后者。尽管数据精准度评价可能也是主观的，有时也有定量的方法可以使用。可以重新采样并且统计和已存储的数据比较，从而测量出精准度。

你会遇到的最普遍情况是丢失或者信息不完整。这里有两种最基本处理丢失数据的策略－删除和填补。在前者中，全面观察分析，减少样本量，潜在地引入偏差，填补丢失或者错误的数据，可以使用多种技术，例如随机取样（就近补齐）、平均值取代，统计分布或者模型等。

#### 专家建议

找到有效的方法，实施，行动。你担心最优化，可以在递增提升中逐步改进方法。

#### 时间序列模型化

在我们的一个项目中，我要找出时间序列和各种参数的相关关系。我们最开始的分析表明了大部分之间不存在相关关系。我们验证了数据，很快发现了数据准确性问题。数据里有丢失数据和空值数据，和消极的观测值（负值），一种内容中不可能出现的测量值（看下图－清理前的数据）。垃圾数据意味着垃圾结果。 

![](http://i4.piimg.com/f84860262ead830f.png)

因为样本已经足够小了，删除观测值是不理想的。时间序列不稳定的本质意味着采样填补的数据是不可信的。最终，我们很快想到了最好的解决策略是过滤和矫正数据里的噪音。

我们最开始尝试了简化方法－通过移动平均去代替观测值。在纠正某些噪音的时候，移动时间序列包括离群点的移动平均计算。这样在底层信号中造成了不合理想的扭曲，于是我们很快放弃了这张方法。

我们队伍中的一个在信号处理有丰富经验的成员推荐了用中值滤波器。中值滤波器是移动窗口内的点，然后用中间值计算当前窗。我们试验了多种窗口大小找到一个可接受的权衡在噪音平滑和信号平滑。下图，清理后的时间序列数据，展示了中间值滤波器填补后的两种时间序列。

![](http://i4.piimg.com/7aaee8a5eb7dc935.png)

中间值滤波器的应用方法得到了巨大的成功。时间序列图可视化检验揭露了在没有抑制自然出现的峰值和谷值（数据丢失）下平滑了离群点。在平滑前，我们的数据中得不出相关关系，平滑后，大部分参数的Spearman相关系数是0.5，通过处理数据准确性问题，我们能够分析出黄金。当其他途径可能已经证明有效的时候，填补方法实施的速度限制了我们进行任何更深入的分析。之后我们取得了成功，并转移到解决问题的其他方面。