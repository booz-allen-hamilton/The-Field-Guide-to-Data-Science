### 集成模型

> 没有任何一个人能比所有人聪明，只有一部分人比其他人聪明。

在 1906 年，弗朗西斯-高尔顿出任一项猜测公牛体重比赛的评审。高尔顿收集了 787 位参赛者的猜测值并计算平均值。出乎他的意料，平均值仅仅比公牛真实体重 1198 磅少一磅。共同的，聚集许多业余者预测比一个专家预测更精确。

高尔顿的 『人群智慧』 扩展到数据科学则是集成学习，也可以非正式地称为集成、混合或者重叠。一种集成将各个模型的预测值集合到一起成为一个新的预测值。就像人们猜测公牛的体重，数据科学模型有独特的优势和劣势（例如，由他们的设计所决定），会被基于以前经验的多种观点所影响（例如，他们已经观察了数据）。

集成克服了个人的弱点，做出比各自模型更精准的预测结果。这些模型不需要加入其他方法的主干，一种集成可能使用同样的方法应对不同参数或者比重（例如，boosting算法），特征集合（例如，随机森林算法），或者重采样（子样本集）数据（例如，bagging算法）。集成的方法可以简单到一分为二（集成的方法可以简单到两个输出的平均），也可以复杂到使用“元模型”去学习出最优结合。

集成能够利用成员的多样性来降低个体的误差。如果一个模型过度拟合数据，可以用欠拟合的模型来平衡它。如果某个子集倾斜，可以加入没有离群值的子集。如果一种方法噪声输入不稳定，可以增加另外一种更加稳定的方法。

训练中，集成常常提高模型少许百分比。这种精准度的代价是增加了复杂度。精准度与复杂度的取舍使得难以判定什么时候使用集成是合适的。一方面，集成似乎为了合适而付出高风险代价－－想想根据 MRI 图像和在传送带上判断未成熟的蓝莓。另一方面，高风险问题需要更高的审计模型实用性标准。

数据科学家必须掌握好集成可解释性和黑箱复杂度的平衡。这可不像表面上看起来这么简单！试着当自己正坐在一辆机器学习编程自驾车的驾驶员座位上。如果一个好的回归模型99.5%做出正确决定，而一个复杂的、低解释性的集成99.8%做出正确决定，你会如何挑选呢？

#### 集成模型的价值

几年前，Kaggle 图像质量预测竞赛出了一个问题：『给定成千组图像隐藏信息，预测哪些人们会打分标记为 ‘好’ 图。』，提供给参赛者大量的用户产生图片。目标是生成一个能够自动从集合中挑选出好的、令人印象深刻的图片。

整个比赛进行后，207 人提交了作品。作品中使用对数似然度量来评价精确度。前 50 队伍的分数在 0.18434 到 0.19884 之间，分数越低越好。Kaggle 数据科学家本-哈姆纳使用了结果去例证了前 50 得分平均值的集成价值。下图展示了结果：

![](http://i4.piimg.com/8c417e33feff44fc.png)

蓝色线展示了前 50 队的各自分数。橘色线展示了前 n 队的集成分数，n 的范围是从 1 到轴值。例如，集成分数在横轴（Final Team Rank）为 5是的分数是队伍 1 到队伍 5 的集成结果。如图所示，集成分数比任何单独一队的分数还低。集成模型的多样性使得相互偏差互相抵消，从而生成一个总体上更低的分数。这个在前 50 队的所有点来看都是成立的。但是，当我们提高模型数大于 15 后，我们开始看到集成分数提升了。这种现象是因为我们引入了低精确模型（例如，隐藏的过度拟合）进入集成中。这次简单试验的结果衡量了创造集成模型的价值，在挑选个体模型时进入集成时，我们必须三思后行。